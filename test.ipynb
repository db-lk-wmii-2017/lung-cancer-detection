{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/anaconda3/envs/lung-cancer-detection/lib/python3.7/site-packages/tflearn/helpers/summarizer.py:9: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/lung-cancer-detection/lib/python3.7/site-packages/tflearn/helpers/trainer.py:25: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/lung-cancer-detection/lib/python3.7/site-packages/tflearn/collections.py:13: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/lung-cancer-detection/lib/python3.7/site-packages/tflearn/config.py:123: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/lung-cancer-detection/lib/python3.7/site-packages/tflearn/config.py:129: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/lung-cancer-detection/lib/python3.7/site-packages/tflearn/config.py:131: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from cnn_model import CNNModel\n",
    "from utils import TRAIN_DATA_FILE_NAME, TEST_DATA_FILE_NAME\n",
    "import tflearn\n",
    "\n",
    "DATA_PATH = 'data/model'\n",
    "MODEL_OUTPUT = 'data/model'\n",
    "\n",
    "VERSION = \"alpha0.0.1\" \n",
    "CLASSIFIER_NAME = \"{}-classifier.tf1\".format(VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 17  | total loss: \u001b[1m\u001b[32m0.92736\u001b[0m\u001b[0m | time: 0.163s\n",
      "| Adam | epoch: 003 | loss: 0.92736 - acc: 0.6707 -- iter: 5/6\n",
      "Training Step: 18  | total loss: \u001b[1m\u001b[32m0.63587\u001b[0m\u001b[0m | time: 1.197s\n",
      "| Adam | epoch: 003 | loss: 0.63587 - acc: 0.7847 | val_loss: 1.57587 - val_acc: 0.5000 -- iter: 6/6\n",
      "--\n",
      "INFO:tensorflow:/Users/lukasz/studies/lung-cancer-detection/data/model/alpha0.0.1-classifier.tf1-18 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "INFO:tensorflow:/Users/lukasz/studies/lung-cancer-detection/data/model/alpha0.0.1-classifier.tf1 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Network trained and saved as alpha0.0.1-classifier.tf1\n"
     ]
    }
   ],
   "source": [
    "def get_data_from_file(path):\n",
    "    data = []\n",
    "    labels = []\n",
    "    with open(path) as file: \n",
    "        while True: \n",
    "            line = file.readline() \n",
    "            if not line: \n",
    "                break\n",
    "    \n",
    "            sample_path, label = line.split(' ')\n",
    "            data.append(np.load(sample_path))\n",
    "            labels.append([0.0, 1.0] if int(label) else [1.0, 0.0])\n",
    "    return np.asarray(data, dtype='f').reshape([-1, 50, 50, 1]) / 255.0, np.asarray(labels, dtype='f')\n",
    "\n",
    "X, Y = get_data_from_file(os.path.join(DATA_PATH, TRAIN_DATA_FILE_NAME))       \n",
    "X_test, Y_text = get_data_from_file(os.path.join(DATA_PATH, TEST_DATA_FILE_NAME))  \n",
    "\n",
    "convnet  = CNNModel()\n",
    "network = convnet.define_network(X)\n",
    "model = tflearn.DNN(network, tensorboard_verbose=0, checkpoint_path=os.path.join(MODEL_OUTPUT, CLASSIFIER_NAME))\n",
    "model.fit(X, Y, n_epoch = 3, shuffle=True,\n",
    "          validation_set = (X_test, Y_text), show_metric = True,\n",
    "          batch_size = 1, snapshot_epoch = True, run_id = VERSION)\n",
    "model.save(os.path.join(MODEL_OUTPUT, CLASSIFIER_NAME))\n",
    "print(\"Network trained and saved as {}\".format(CLASSIFIER_NAME))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "# Load HDF5 dataset\n",
    "h5f = h5py.File('train.h5', 'r')\n",
    "X_train_images = h5f['X']\n",
    "Y_train_labels = h5f['Y']\n",
    "\n",
    "h5f2 = h5py.File('test.h5', 'r')\n",
    "X_val_images = h5f2['X']\n",
    "Y_val_labels = h5f2['Y']\n",
    "\n",
    "print(Y_val_labels[0])\n",
    "# ## Model definition\n",
    "# convnet  = CNNModel()\n",
    "# network = convnet.define_network(X_train_images)\n",
    "# model = tflearn.DNN(network, tensorboard_verbose=0,\\\n",
    "# \t\t checkpoint_path='nodule3-classifier.tfl.ckpt')\n",
    "# model.fit(X_train_images, Y_train_labels, n_epoch = 70, shuffle=True,\\\n",
    "# \t\t\tvalidation_set = (X_val_images, Y_val_labels), show_metric = True,\\\n",
    "# \t\t\tbatch_size = 96, snapshot_epoch = True, run_id = 'nodule3-classifier')\n",
    "# model.save(\"nodule3-classifier.tfl\")\n",
    "# print(\"Network trained and saved as nodule2-classifier.tfl!\")\n",
    "# h5f.close()\n",
    "# h5f2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lung-cancer-detection",
   "language": "python",
   "name": "lung-cancer-detection"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
