{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curses is not supported on this machine (please install/reinstall curses for an optimal experience)\n",
      "WARNING:tensorflow:From E:\\anconda\\envs\\lung-cancer-detection\\lib\\site-packages\\tflearn\\helpers\\summarizer.py:9: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.\n",
      "\n",
      "WARNING:tensorflow:From E:\\anconda\\envs\\lung-cancer-detection\\lib\\site-packages\\tflearn\\helpers\\trainer.py:25: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "WARNING:tensorflow:From E:\\anconda\\envs\\lung-cancer-detection\\lib\\site-packages\\tflearn\\collections.py:13: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:From E:\\anconda\\envs\\lung-cancer-detection\\lib\\site-packages\\tflearn\\config.py:123: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From E:\\anconda\\envs\\lung-cancer-detection\\lib\\site-packages\\tflearn\\config.py:129: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From E:\\anconda\\envs\\lung-cancer-detection\\lib\\site-packages\\tflearn\\config.py:131: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from cnn_model import CNNModel\n",
    "from utils import TRAIN_DATA_FILE_NAME, TEST_DATA_FILE_NAME\n",
    "import tflearn\n",
    "\n",
    "DATA_PATH = os.path.join('data', 'model')\n",
    "MODEL_OUTPUT = os.path.join('data', 'model')\n",
    "\n",
    "VERSION = \"alpha0.0.1\" \n",
    "CLASSIFIER_NAME = \"{}-classifier.tf1\".format(VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\\preprocessed\\1.3.6.1.4.1.14519.5.2.1.6279.6001.172845185165807139298420209778\\131080-0.npy\n",
      "data\\preprocessed\\1.3.6.1.4.1.14519.5.2.1.6279.6001.177888806135892723698313903329\\144975-0.npy\n"
     ]
    }
   ],
   "source": [
    "def get_data_from_file(path):\n",
    "    data = []\n",
    "    labels = []\n",
    "    with open(path) as file: \n",
    "        while True: \n",
    "            line = file.readline() \n",
    "            if not line: \n",
    "                break\n",
    "            \n",
    "            sample_path, label = line.split(' ')\n",
    "            array = np.load(sample_path)\n",
    "            if array.shape == (50, 50):\n",
    "                data.append(array)\n",
    "                labels.append([0.0, 1.0] if int(label) else [1.0, 0.0])\n",
    "            else:\n",
    "                print(sample_path)  \n",
    "    return np.asarray(data, dtype='f').reshape([-1, 50, 50, 1]) / 255.0, np.asarray(labels, dtype='f')\n",
    "\n",
    "X, Y = get_data_from_file(os.path.join(DATA_PATH, TRAIN_DATA_FILE_NAME))       \n",
    "# X_test, Y_text = get_data_from_file(os.path.join(DATA_PATH, TEST_DATA_FILE_NAME))  \n",
    "\n",
    "# convnet  = CNNModel()\n",
    "# network = convnet.define_network(X)\n",
    "# model = tflearn.DNN(network, tensorboard_verbose=0, checkpoint_path=os.path.join(MODEL_OUTPUT, CLASSIFIER_NAME))\n",
    "# model.fit(X, Y, n_epoch = 3, shuffle=True,\n",
    "#           validation_set = (X_test, Y_text), show_metric = True,\n",
    "#           batch_size = 1, snapshot_epoch = True, run_id = VERSION)\n",
    "# model.save(os.path.join(MODEL_OUTPUT, CLASSIFIER_NAME))\n",
    "# print(\"Network trained and saved as {}\".format(CLASSIFIER_NAME))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import h5py\n",
    "\n",
    "# # Load HDF5 dataset\n",
    "# h5f = h5py.File('train.h5', 'r')\n",
    "# X_train_images = h5f['X']\n",
    "# Y_train_labels = h5f['Y']\n",
    "\n",
    "# h5f2 = h5py.File('test.h5', 'r')\n",
    "# X_val_images = h5f2['X']\n",
    "# Y_val_labels = h5f2['Y']\n",
    "\n",
    "# print(Y_val_labels[0])\n",
    "# # ## Model definition\n",
    "# # convnet  = CNNModel()\n",
    "# # network = convnet.define_network(X_train_images)\n",
    "# # model = tflearn.DNN(network, tensorboard_verbose=0,\\\n",
    "# # \t\t checkpoint_path='nodule3-classifier.tfl.ckpt')\n",
    "# # model.fit(X_train_images, Y_train_labels, n_epoch = 70, shuffle=True,\\\n",
    "# # \t\t\tvalidation_set = (X_val_images, Y_val_labels), show_metric = True,\\\n",
    "# # \t\t\tbatch_size = 96, snapshot_epoch = True, run_id = 'nodule3-classifier')\n",
    "# # model.save(\"nodule3-classifier.tfl\")\n",
    "# # print(\"Network trained and saved as nodule2-classifier.tfl!\")\n",
    "# # h5f.close()\n",
    "# # h5f2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lung-cancer-detection",
   "language": "python",
   "name": "lung-cancer-detection"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
